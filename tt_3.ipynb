{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ae23cfd-80cf-43ef-a42d-8d315f3524a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79636725-7730-48ab-9472-3bb1b68856b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21c6c343-3b96-4c46-b4fb-5c512b2c0062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18347 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load Training Data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'train_tomato',\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc9d45fa-ac6e-4607-83d4-ac04b5a22817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4585 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load Validation Data\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    'valid_tomato',\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62b5f8aa-9ce0-41de-b072-521be55c2840",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense,Conv2D,MaxPool2D,Flatten,Dropout\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13a786c2-d1c5-4e1a-a74e-ae7f432db7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37838310-9caa-4c7e-88a3-cb57552be183",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters=16,kernel_size=1,padding='same',activation='relu',input_shape=[128,128,3]))\n",
    "model.add(Conv2D(filters=16,kernel_size=1,activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73f2b343-4ea4-4f04-8b15-6d1638ba04d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters=32,kernel_size=1,padding='same',activation='relu'))\n",
    "model.add(Conv2D(filters=32,kernel_size=1,activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "084e0b04-b420-4b08-ad0b-c9c35116a33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters=64,kernel_size=1,padding='same',activation='relu'))\n",
    "model.add(Conv2D(filters=64,kernel_size=1,activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4286c7c-50cf-40fd-b0d8-7fc54d68ff60",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters=128,kernel_size=4,padding='same',activation='relu'))\n",
    "model.add(Conv2D(filters=128,kernel_size=4,activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72e79ff5-0d1c-46cf-b32b-112471a4c225",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters=256,kernel_size=2,padding='same',activation='relu'))\n",
    "model.add(Conv2D(filters=256,kernel_size=2,activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ec3f3d7-eb80-4d83-8ee6-916503448181",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.25))   #To avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a72206d0-d005-430c-81ef-05d0f3d1e05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aee4351f-193b-49fe-adad-6340711b40e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=1000,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "073971f8-2385-4075-849d-a0e8b8d427b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e549de12-8ca8-47d8-8a58-ac8fad96b554",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output Layer\n",
    "model.add(Dense(units=10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee02ec01-bad0-4286-bc78-1f2ef5037f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Nadam(\n",
    "    learning_rate=0.0001),loss='categorical_crossentropy',metrics=['accuracy'])   #Adagrad, Adamax, Nadam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6c6a808-7506-4217-a139-95ff5ded42a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 128, 128, 16)      64        \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 128, 128, 16)      272       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 64, 64, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 64, 64, 32)        544       \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 64, 64, 32)        1056      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 32, 32, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 32, 32, 64)        2112      \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 32, 32, 64)        4160      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 16, 16, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 16, 16, 128)       131200    \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 13, 13, 128)       262272    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 6, 6, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 6, 6, 256)         131328    \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 5, 5, 256)         262400    \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 2, 2, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2, 2, 256)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1000)              1025000   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                10010     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,830,418\n",
      "Trainable params: 1,830,418\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "463fd341-6b91-4a67-88f9-7373f04bce74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "574/574 [==============================] - 214s 355ms/step - loss: 1.8504 - accuracy: 0.3079 - val_loss: 1.4337 - val_accuracy: 0.4696\n",
      "Epoch 2/40\n",
      "574/574 [==============================] - 233s 405ms/step - loss: 1.2377 - accuracy: 0.5472 - val_loss: 1.0221 - val_accuracy: 0.6257\n",
      "Epoch 3/40\n",
      "574/574 [==============================] - 202s 352ms/step - loss: 0.9377 - accuracy: 0.6678 - val_loss: 0.7163 - val_accuracy: 0.7431\n",
      "Epoch 4/40\n",
      "574/574 [==============================] - 199s 346ms/step - loss: 0.7075 - accuracy: 0.7498 - val_loss: 0.6221 - val_accuracy: 0.7749\n",
      "Epoch 5/40\n",
      "574/574 [==============================] - 155s 270ms/step - loss: 0.5686 - accuracy: 0.7966 - val_loss: 0.4502 - val_accuracy: 0.8434\n",
      "Epoch 6/40\n",
      "574/574 [==============================] - 119s 208ms/step - loss: 0.4843 - accuracy: 0.8283 - val_loss: 0.3662 - val_accuracy: 0.8656\n",
      "Epoch 7/40\n",
      "574/574 [==============================] - 127s 221ms/step - loss: 0.4316 - accuracy: 0.8456 - val_loss: 0.3386 - val_accuracy: 0.8807\n",
      "Epoch 8/40\n",
      "574/574 [==============================] - 127s 221ms/step - loss: 0.3811 - accuracy: 0.8658 - val_loss: 0.3288 - val_accuracy: 0.8844\n",
      "Epoch 9/40\n",
      "574/574 [==============================] - 124s 216ms/step - loss: 0.3432 - accuracy: 0.8780 - val_loss: 0.3118 - val_accuracy: 0.8870\n",
      "Epoch 10/40\n",
      "574/574 [==============================] - 126s 219ms/step - loss: 0.3159 - accuracy: 0.8865 - val_loss: 0.3581 - val_accuracy: 0.8707\n",
      "Epoch 11/40\n",
      "574/574 [==============================] - 136s 237ms/step - loss: 0.2864 - accuracy: 0.8982 - val_loss: 0.2924 - val_accuracy: 0.8947\n",
      "Epoch 12/40\n",
      "574/574 [==============================] - 130s 227ms/step - loss: 0.2714 - accuracy: 0.9045 - val_loss: 0.2063 - val_accuracy: 0.9296\n",
      "Epoch 13/40\n",
      "574/574 [==============================] - 119s 207ms/step - loss: 0.2481 - accuracy: 0.9117 - val_loss: 0.2950 - val_accuracy: 0.8968\n",
      "Epoch 14/40\n",
      "574/574 [==============================] - 121s 211ms/step - loss: 0.2391 - accuracy: 0.9178 - val_loss: 0.2387 - val_accuracy: 0.9145\n",
      "Epoch 15/40\n",
      "574/574 [==============================] - 121s 210ms/step - loss: 0.2262 - accuracy: 0.9229 - val_loss: 0.3578 - val_accuracy: 0.8707\n",
      "Epoch 16/40\n",
      "574/574 [==============================] - 122s 212ms/step - loss: 0.2069 - accuracy: 0.9272 - val_loss: 0.1967 - val_accuracy: 0.9293\n",
      "Epoch 17/40\n",
      "574/574 [==============================] - 122s 212ms/step - loss: 0.1978 - accuracy: 0.9297 - val_loss: 0.2024 - val_accuracy: 0.9278\n",
      "Epoch 18/40\n",
      "574/574 [==============================] - 125s 218ms/step - loss: 0.1865 - accuracy: 0.9306 - val_loss: 0.1792 - val_accuracy: 0.9398\n",
      "Epoch 19/40\n",
      "574/574 [==============================] - 125s 218ms/step - loss: 0.1781 - accuracy: 0.9373 - val_loss: 0.2587 - val_accuracy: 0.9067\n",
      "Epoch 20/40\n",
      "574/574 [==============================] - 121s 210ms/step - loss: 0.1696 - accuracy: 0.9404 - val_loss: 0.1343 - val_accuracy: 0.9492\n",
      "Epoch 21/40\n",
      "574/574 [==============================] - 119s 207ms/step - loss: 0.1574 - accuracy: 0.9440 - val_loss: 0.1419 - val_accuracy: 0.9481\n",
      "Epoch 22/40\n",
      "574/574 [==============================] - 121s 210ms/step - loss: 0.1546 - accuracy: 0.9441 - val_loss: 0.1684 - val_accuracy: 0.9409\n",
      "Epoch 23/40\n",
      "574/574 [==============================] - 121s 210ms/step - loss: 0.1450 - accuracy: 0.9494 - val_loss: 0.1613 - val_accuracy: 0.9446\n",
      "Epoch 24/40\n",
      "574/574 [==============================] - 121s 211ms/step - loss: 0.1398 - accuracy: 0.9510 - val_loss: 0.1644 - val_accuracy: 0.9385\n",
      "Epoch 25/40\n",
      "574/574 [==============================] - 124s 215ms/step - loss: 0.1370 - accuracy: 0.9497 - val_loss: 0.1503 - val_accuracy: 0.9442\n",
      "Epoch 26/40\n",
      "574/574 [==============================] - 123s 214ms/step - loss: 0.1320 - accuracy: 0.9542 - val_loss: 0.1415 - val_accuracy: 0.9505\n",
      "Epoch 27/40\n",
      "574/574 [==============================] - 123s 215ms/step - loss: 0.1201 - accuracy: 0.9576 - val_loss: 0.1428 - val_accuracy: 0.9481\n",
      "Epoch 28/40\n",
      "574/574 [==============================] - 155s 270ms/step - loss: 0.1188 - accuracy: 0.9569 - val_loss: 0.1402 - val_accuracy: 0.9498\n",
      "Epoch 29/40\n",
      "574/574 [==============================] - 129s 225ms/step - loss: 0.1166 - accuracy: 0.9579 - val_loss: 0.1552 - val_accuracy: 0.9487\n",
      "Epoch 30/40\n",
      "574/574 [==============================] - 107s 186ms/step - loss: 0.1164 - accuracy: 0.9597 - val_loss: 0.1757 - val_accuracy: 0.9330\n",
      "Epoch 31/40\n",
      "574/574 [==============================] - 96s 168ms/step - loss: 0.1066 - accuracy: 0.9617 - val_loss: 0.1392 - val_accuracy: 0.9525\n",
      "Epoch 32/40\n",
      "574/574 [==============================] - 101s 175ms/step - loss: 0.1058 - accuracy: 0.9614 - val_loss: 0.1702 - val_accuracy: 0.9402\n",
      "Epoch 33/40\n",
      "574/574 [==============================] - 105s 183ms/step - loss: 0.0971 - accuracy: 0.9654 - val_loss: 0.1192 - val_accuracy: 0.9592\n",
      "Epoch 34/40\n",
      "574/574 [==============================] - 102s 177ms/step - loss: 0.1001 - accuracy: 0.9644 - val_loss: 0.1205 - val_accuracy: 0.9597\n",
      "Epoch 35/40\n",
      "574/574 [==============================] - 98s 171ms/step - loss: 0.0952 - accuracy: 0.9656 - val_loss: 0.1015 - val_accuracy: 0.9627\n",
      "Epoch 36/40\n",
      "574/574 [==============================] - 108s 188ms/step - loss: 0.0925 - accuracy: 0.9665 - val_loss: 0.1306 - val_accuracy: 0.9546\n",
      "Epoch 37/40\n",
      "574/574 [==============================] - 104s 180ms/step - loss: 0.0859 - accuracy: 0.9702 - val_loss: 0.1050 - val_accuracy: 0.9603\n",
      "Epoch 38/40\n",
      "574/574 [==============================] - 101s 175ms/step - loss: 0.0950 - accuracy: 0.9663 - val_loss: 0.1158 - val_accuracy: 0.9618\n",
      "Epoch 39/40\n",
      "574/574 [==============================] - 104s 181ms/step - loss: 0.0824 - accuracy: 0.9699 - val_loss: 0.0781 - val_accuracy: 0.9740\n",
      "Epoch 40/40\n",
      "574/574 [==============================] - 104s 182ms/step - loss: 0.0870 - accuracy: 0.9700 - val_loss: 0.1331 - val_accuracy: 0.9525\n"
     ]
    }
   ],
   "source": [
    "training_history = model.fit(x=train_generator,validation_data=validation_generator,epochs=40) ## Epoch set for max accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ea9d6e7-0427-4e02-823a-e57ee23b6576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 7s 49ms/step - loss: 0.1331 - accuracy: 0.9525\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "val_loss,val_acc = model.evaluate(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4adfa4ad-a013-4729-b265-bd2a0f26c1df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Tomato___Bacterial_spot': 0,\n",
       " 'Tomato___Early_blight': 1,\n",
       " 'Tomato___Late_blight': 2,\n",
       " 'Tomato___Leaf_Mold': 3,\n",
       " 'Tomato___Septoria_leaf_spot': 4,\n",
       " 'Tomato___Spider_mites Two-spotted_spider_mite': 5,\n",
       " 'Tomato___Target_Spot': 6,\n",
       " 'Tomato___Tomato_Yellow_Leaf_Curl_Virus': 7,\n",
       " 'Tomato___Tomato_mosaic_virus': 8,\n",
       " 'Tomato___healthy': 9}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_name = validation_generator.class_indices\n",
    "class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a9f2deaa-d057-44fe-9b27-276bde91367d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4585 files belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    'valid_tomato',\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(128, 128),\n",
    "    shuffle=False,\n",
    "    seed=None,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e795293d-813c-4c12-868e-6d502eb85154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 2s 15ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(test_set)\n",
    "predicted_categories = tf.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e21f693-f302-433a-b50c-9eb3acfde1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_categories = tf.concat([y for x, y in test_set], axis=0)\n",
    "Y_true = tf.argmax(true_categories, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7d6391f-8515-4a85-a4e2-1cf3c7beb0d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4585,), dtype=int64, numpy=array([0, 0, 0, ..., 9, 9, 9], dtype=int64)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bf0d46fc-cc95-4287-b3c2-e1c10a73ce98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4585,), dtype=int64, numpy=array([8, 8, 6, ..., 8, 6, 8], dtype=int64)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "53075e8c-3db1-44e5-b2e0-52f148028654",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"tm_2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db32c028-6a9f-47c0-aebe-1f50bfd5132c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
